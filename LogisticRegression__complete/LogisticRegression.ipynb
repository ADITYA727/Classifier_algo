{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as j\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- read and transform json file\n",
    "data = pd.read_csv('data_large_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "data['tweets'] = data['tweets'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.tweets\n",
    "y = data.tagname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\hp\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "count = CountVectorizer()\n",
    "temp = count.fit_transform(X_train)\n",
    "\n",
    "tdif = TfidfTransformer()\n",
    "temp2 = tdif.fit_transform(temp)\n",
    "\n",
    "text_regression = LogisticRegression()\n",
    "model = text_regression.fit(temp2, y_train)\n",
    "\n",
    "prediction_data = tdif.transform(count.transform(X_test))\n",
    "\n",
    "predicted = model.predict(prediction_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  results  already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "dirName = 'results'\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "## predictions for first 10 test samples\n",
    "text_hollywood = ''\n",
    "text_bollywood = ''\n",
    "text_ml = ''\n",
    "text_football = ''\n",
    "text_bigg_boss = ''\n",
    "text_food = '' \n",
    "text_hp_day = ''\n",
    "text_politics = ''\n",
    "text_mobiles = ''\n",
    "text_cricket = ''\n",
    "counter  = 0\n",
    "for doc, category in zip(X_test, predicted):\n",
    "    if category == \"hollywood\":\n",
    "        f= open('results/'+ category+\".txt\",\"w+\")\n",
    "        if (text_hollywood != \"\"):\n",
    "            text_hollywood = text_hollywood + '\\n' + doc\n",
    "        else:\n",
    "            text_hollywood = doc\n",
    "        f.write(text_hollywood)\n",
    "        f.close()\n",
    "    if category == \"bollywood\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_bollywood != \"\"):\n",
    "            text_bollywood = text_bollywood + '\\n' + doc\n",
    "        else:\n",
    "            text_bollywood = doc\n",
    "        f.write(text_bollywood)\n",
    "        f.close()\n",
    "    if category == \"machine learning\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_ml != \"\"):\n",
    "            text_ml = text_ml + '\\n' + doc\n",
    "        else:\n",
    "            text_ml = doc\n",
    "        f.write(text_ml)\n",
    "        f.close()\n",
    "    if category == \"football\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_football != \"\"):\n",
    "            text_football = text_football + '\\n' + doc\n",
    "        else:\n",
    "            text_football = doc\n",
    "        f.write(text_football)\n",
    "        f.close()\n",
    "    if category == \"bigg boss\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_bigg_boss != \"\"):\n",
    "            text_bigg_boss = text_bigg_boss + '\\n' + doc\n",
    "        else:\n",
    "            text_bigg_boss = doc\n",
    "        f.write(text_bigg_boss)\n",
    "        f.close()\n",
    "    if category == \"food\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_food != \"\"):\n",
    "            text_food = text_food + '\\n' + doc\n",
    "        else:\n",
    "            text_food = doc\n",
    "        f.write(text_food)\n",
    "        f.close()\n",
    "    if category == \"happy birthday\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_hp_day != \"\"):\n",
    "            text_hp_day = text_hp_day + '\\n' + doc\n",
    "        else:\n",
    "            text_hp_day = doc\n",
    "        f.write(text_hp_day)\n",
    "        f.close() \n",
    "    if category == \"politics\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_politics != \"\"):\n",
    "            text_politics = text_politics + '\\n' + doc\n",
    "        else:\n",
    "            text_politics = doc\n",
    "        f.write(text_politics)\n",
    "        f.close() \n",
    "    if category == \"mobiles\":\n",
    "        f= open('results/'+category+\".txt\",\"w+\")\n",
    "        if (text_mobiles != \"\"):\n",
    "            text_mobiles = text_mobiles + '\\n' + doc\n",
    "        else:\n",
    "            text_mobiles = doc\n",
    "        f.write(text_mobiles)\n",
    "        f.close()\n",
    "    if category == \"cricket\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_cricket != \"\"):\n",
    "            text_cricket = text_cricket + '\\n' + doc\n",
    "        else:\n",
    "            text_cricket = doc\n",
    "        f.write(text_cricket)\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9610481586402266\n",
      "['food']\n"
     ]
    }
   ],
   "source": [
    "# instead of doing all this steps above one could also use Pipeline\n",
    "# this is a more compact way of writing the code above...\n",
    "# it also has the benefit that there is no need to perform the transformations on the test data\n",
    "#\n",
    "#\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#text_regression = Pipeline([('count', CountVectorizer()), ('tfidf', TfidfTransformer()),('reg', LogisticRegression())])\n",
    "#\n",
    "#model = text_regression.fit(X_train.text, y_train)\n",
    "#predicted = model.predict(X_test.text)\n",
    "\n",
    "\n",
    "# --- make predictions\n",
    "\n",
    "\n",
    "print(np.mean(predicted == y_test))\n",
    "\n",
    "# --- have some fun with the model\n",
    "\n",
    "print(model.predict(tdif.transform(count.transform([\"Khana\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
