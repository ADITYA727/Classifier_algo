{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "# Naive Bayes Classification(✔)\n",
    "# Support vector machines for classification problems\n",
    "# Random forest for classification and regression problems\n",
    "# Linear regression for regression problems\n",
    "# Ordinary Least Squares Regression\n",
    "# Logistic Regression\n",
    "# Ensemble Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as skd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['bollywood', 'hollywood','politics', 'cricket','food','football','mobiles','machine learning','bigg boss','happy birthday']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data From CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_large_5000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>tagname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>amp TeamIndia IndvsBan DayandNightTest PinkBal...</td>\n",
       "      <td>cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>BharatArmyAwards Here are the nominees for th...</td>\n",
       "      <td>cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ALE TeamIndia for the upcoming series against...</td>\n",
       "      <td>cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Getting into PinkBallTest mode TeamIndia INDvBAN</td>\n",
       "      <td>cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Umpiring in the first ever pink ball match at...</td>\n",
       "      <td>cricket</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4995</td>\n",
       "      <td>MIUI update rolling out for Redmi Plus Note Vi...</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4996</td>\n",
       "      <td>Redmi Note Pro Android development version re...</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4997</td>\n",
       "      <td>Redmi India Hello redmi india number one cells...</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4998</td>\n",
       "      <td>Redmi Note T Mi NFC</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4999</td>\n",
       "      <td>Redmi Note T Mi NFC</td>\n",
       "      <td>mobiles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tweets  tagname\n",
       "0     amp TeamIndia IndvsBan DayandNightTest PinkBal...  cricket\n",
       "1      BharatArmyAwards Here are the nominees for th...  cricket\n",
       "2      ALE TeamIndia for the upcoming series against...  cricket\n",
       "3      Getting into PinkBallTest mode TeamIndia INDvBAN  cricket\n",
       "4      Umpiring in the first ever pink ball match at...  cricket\n",
       "...                                                 ...      ...\n",
       "4995  MIUI update rolling out for Redmi Plus Note Vi...  mobiles\n",
       "4996   Redmi Note Pro Android development version re...  mobiles\n",
       "4997  Redmi India Hello redmi india number one cells...  mobiles\n",
       "4998                                Redmi Note T Mi NFC  mobiles\n",
       "4999                                Redmi Note T Mi NFC  mobiles\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.tweets\n",
    "y = data.tagname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cricket', 'mobiles', 'food', 'machine learning', 'hollywood',\n",
       "       'happy birthday', 'football', 'bollywood', 'bigg boss', 'politics'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data into test(80%) and train(20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7060"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28240"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create linear  pipeline for algorithm first go tf_idf than navies bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', TfidfVectorizer()), ('clf', MultinomialNB()) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, give training our data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "text_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self test\n",
    "a = [\"SRK\"]\n",
    "self_predicted = text_clf.predict(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bollywood\n"
     ]
    }
   ],
   "source": [
    "for x in self_predicted:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the test cases\n",
    "real_predicted = text_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "from gensim import parsing        # Help in preprocessing the data, very efficiently\n",
    "import gensim\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    # Convert text to lower\n",
    "    text = text.lower()\n",
    "    # Removing non ASCII chars    \n",
    "    text = re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Removing all the stopwords\n",
    "    filtered_words = [word for word in text.split() if word not in stops]\n",
    "    \n",
    "    # Removing all the tokens with lesser than 3 characters\n",
    "    filtered_words = gensim.corpora.textcorpus.remove_short(filtered_words, minsize=3)\n",
    "    \n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    \n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation2(text)\n",
    "    \n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    \n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    \n",
    "    # Stemming\n",
    "    return gensim.parsing.preprocessing.stem_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tt = df_train.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @tiffanylue i know  i was listenin to bad habi...\n",
       "1        Layin n bed with a headache  ughhhh...waitin o...\n",
       "2                      Funeral ceremony...gloomy friday...\n",
       "3                     wants to hang out with friends SOON!\n",
       "4        @dannycastillo We want to trade with someone w...\n",
       "                               ...                        \n",
       "39995                                     @JohnLloydTaylor\n",
       "39996                       Happy Mothers Day  All my love\n",
       "39997    Happy Mother's Day to all the mommies out ther...\n",
       "39998    @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
       "39999    @mopedronin bullet train from tokyo    the gf ...\n",
       "Name: tweets, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[' => cricket\n",
      "'Layin n bed with a headache  ughhhh...waitin on your call...' => food\n",
      "'Funeral ceremony...gloomy friday...' => machine learning\n",
      "'wants to hang out with friends SOON!' => cricket\n",
      "'@dannycastillo We want to trade with someone who has Houston tickets, but no one will.' => machine learning\n",
      "\"Re-pinging @ghostridah14: why didn't you go to prom? BC my bf didn't like my friends\" => hollywood\n",
      "\"I should be sleep, but im not! thinking about an old friend who I want. but he's married now. damn, &amp; he wants me 2! scandalous!\" => football\n",
      "'Hmmm. http://www.djhero.com/ is down' => bollywood\n",
      "'@charviray Charlene my love. I miss you' => football\n",
      "\"@kelcouch I'm sorry  at least it's Friday?\" => happy birthday\n",
      "'cant fall asleep' => machine learning\n",
      "'Choked on her retainers' => happy birthday\n",
      "'Ugh! I have to beat this stupid song to get to the next  rude!' => football\n",
      "'@BrodyJenner if u watch the hills in london u will realise what tourture it is because were weeks and weeks late  i just watch itonlinelol' => cricket\n",
      "'Got the news' => bollywood\n",
      "'The storm is here and the electricity is gone' => hollywood\n",
      "'@annarosekerr agreed' => bigg boss\n",
      "\"So sleepy again and it's not even that late. I fail once again.\" => bollywood\n",
      "'@PerezHilton lady gaga tweeted about not being impressed by her video leaking just so you know' => cricket\n",
      "'How are YOU convinced that I have always wanted you? What signals did I give off...damn I think I just lost another friend' => happy birthday\n",
      "\"@raaaaaaek oh too bad! I hope it gets better. I've been having sleep issues lately too\" => bollywood\n",
      "\"Wondering why I'm awake at 7am,writing a new song,plotting my evil secret plots muahahaha...oh damn it,not secret anymore\" => machine learning\n",
      "'No Topic Maps talks at the Balisage Markup Conference 2009   Program online at http://tr.im/mL6Z (via @bobdc) #topicmaps' => machine learning\n",
      "\"I ate Something I don't know what it is... Why do I keep Telling things about food\" => hollywood\n",
      "\"so tired and i think i'm definitely going to get an ear infection.  going to bed &quot;early&quot; for once.\" => food\n",
      "'On my way home n having 2 deal w underage girls drinking gin on da bus while talking bout keggers......damn i feel old' => bollywood\n",
      "\"@IsaacMascote  i'm sorry people are so rude to you, isaac, they should get some manners and know better than to be so lewd!\" => bigg boss\n",
      "'Damm servers still down  i need to hit 80 before all the koxpers pass me' => cricket\n",
      "\"Fudge.... Just BS'd that whole paper.... So tired.... Ugh I hate school.....  time to sleep!!!!!!!!!!!\" => food\n",
      "'I HATE CANCER. I HATE IT I HATE IT I HATE IT.' => hollywood\n",
      "'It is so annoying when she starts typing on her computer in the middle of the night!' => bollywood\n",
      "'@cynthia_123 i cant sleep' => cricket\n",
      "'I missed the bl***y bus!!!!!!!!' => bollywood\n",
      "'feels strong contractions but wants to go out.  http://plurk.com/p/wxidk' => machine learning\n",
      "'SoCal!  stoked. or maybe not.. tomorrow' => bollywood\n",
      "'Screw you @davidbrussee! I only have 3 weeks...' => bollywood\n",
      "\"@ether_radio yeah :S i feel all funny cause i haven't slept enough  i woke my mum up cause i was singing she's not impressed :S you?\" => bollywood\n",
      "'I need skott right now' => mobiles\n",
      "'has work this afternoon' => food\n",
      "'@GABBYiSACTiVE Aw you would not unfollow me would you? Then I would cry' => bigg boss\n",
      "\"mmm much better day... so far! it's still quite early. last day of #uds\" => bollywood\n",
      "'@DavidArchie &lt;3 your gonna be the first  twitter ;) cause your amazing lol. come to canada  would do anything to see you perform' => happy birthday\n",
      "'just picked up her Blackberry from the middle of the street! Both she and it are crushed!' => bigg boss\n",
      "\"Why do I have the feeling I should be packing and hitting for SFO around this time of the year? I think I'm missing something...\" => food\n",
      "'@creyes middle school and elem. High schools will remain open for those who need credits to graduate. Cali is broken' => hollywood\n",
      "\"Bed!!!!!... its time,..... hope i go to school tomorrow, all though i don't feel very well right now\" => hollywood\n",
      "'@onscrn Ahh.  ... Well, I was hoping that I could learn some stuff on the way. ... Why not you and I work on separate things but also' => happy birthday\n",
      "\"I'm having a problem with my photo here in twitter amf!!!...can't see my face!\" => happy birthday\n",
      "\"@jakeboyd, oh noooo!  if i blow a tire you're reaaaally going to have to send up some batman smoke.\" => bollywood\n",
      "'wnna take a bath!!!!' => cricket\n",
      "'Chocolate milk is so much better through a straw. I lack said straw' => food\n",
      "'why am i so tired?' => food\n",
      "'@djmicdamn hey yu lil fucker i textd yu' => food\n",
      "\"@Mennard time diff and i've just been wrapped up in day to day stuff so i havent been tweeting. talk soon,must sleep...up in 6hrs\" => cricket\n",
      "'@benballer  no way! damn that sucks B!  are you ok?' => cricket\n",
      "'sucks not being able to take days off of work or have the money to take the trip  so sad' => food\n",
      "'bed...sorta. today was good, sara has strep thought Angelina does to; i shared a water with her B4 they told me, i will prob get it to' => football\n",
      "\"@ramtops the recession. her hotel are restructuring how the accounts are done. adds a bit more pressure in the short term but we'll cope\" => mobiles\n",
      "'@lostluna But I got dibs on Sulu...' => bollywood\n",
      "'@maternitytees Aww  Onward and upwards now, yay! Still sad to leave I bet.' => football\n",
      "'@itsgabbith at once haha.  poor aby still gets sore!' => food\n",
      "\"diesel yaris... 70mpg  so sad its not available in the US. That'd be awesome.\" => hollywood\n",
      "'I want to buy this great album but unfortunately i dont hav enuff funds  its &quot;long time noisy&quot;' => machine learning\n",
      "'@Pokinatcha  in all honesty...pain   blech.' => machine learning\n",
      "\"Ok ... the passengers ... no one is alive ... they're all dead ... you just don't know it til the end ... then you cry ...\" => food\n",
      "'At home alone with not much to do' => bollywood\n",
      "\"@DavidCookLove ia so much! i haven't really been happy with any of cooks choices for singles.\" => cricket\n",
      "\"@vincew @stefanyngo  i fell asleep on the beach and didn't put on enough sunscreen  lol\" => food\n",
      "'So i think my son might have the flu cause I def. just cleaned up a stanky puke mess  Poor pumkpin' => football\n",
      "'So great to see Oin &amp; Cynthia.  So happy.  Dinner was great, cute little place.  Too bad Oin got sick afterwards.' => machine learning\n",
      "'I cant give @jertronic any bday nudges.' => cricket\n",
      "\"...and all woman who transfer their first impressions (sexual/maternal) onto a less 'threatening' man -- are themselves as weak as 'Him'\" => cricket\n",
      "\"Brothers Bloom won't be opening this weekend in El Paso.  I'll just buy Brick and enjoy that until I can watch Brothers Bloom.\" => football\n",
      "'says I miss plurking.  http://plurk.com/p/wxion' => mobiles\n",
      "'Bitten to blood by my cat, on my way for a rabies bacterin. Seems 7 shots for 2 months. Never wash my cats at home again, they hate water' => bigg boss\n",
      "'I miss Voobys!' => food\n",
      "'@Dancing_Monk Neither are ELP!!' => bollywood\n",
      "'@havingmysay  dude, that is my favorite sandwich place ever. ummm did you take PICTURES?' => food\n",
      "\"is sad that shin ae got married...and it wasn't to alex\" => hollywood\n",
      "\"@shondarhimes Sure you will tweet about this when you're back, but news is abuzz about TR Knight's leaving &quot;confirmed&quot; today.  Muy triste.\" => bigg boss\n",
      "'@RachelLock22 ohh thursday i have exams.. all day  what about wednesday ?' => cricket\n",
      "'there was a mix up with my dentist appt this afternoon. so they rescheduled me for tomorrow @ 9am.' => bollywood\n",
      "'@gcrush @nopantsdance i was just thinking about how excited i am for you guys to move, but then i realized how sad i am to see you go.' => machine learning\n",
      "'goooood mooorning people... sun is out.. definitly spring now, we had our first spring hail storm, my car has dimples now..' => food\n",
      "\"@artfuldodga I love those 'it'sakey' USB sticks. We only have the 4GB in Australia\" => football\n",
      "'fresh prince and sleepy sleeps my nightly routine  gotta go to Dmv early tmrw' => food\n",
      "\"dammit! hulu desktop has totally screwed up my ability to talk to a particular port on one of our dev servers. so i can't watch and code\" => food\n",
      "'@emmarler i am jealous of your mom talking to @taylorswift13. i want to see you all our twittering is making me miss you' => football\n",
      "\"I can't sleep...I keep thinking about the puppy I played with today\" => machine learning\n",
      "\".. I'm suppposed to be sleep. But i got some much to do. &amp; i got that one part of the song stuck in my head &quot;your a jerk (iknow)&quot;  blaahh\" => bollywood\n",
      "\"@lepetitagneau what's going on sweetheart?\" => bollywood\n",
      "\"How can it be so freaking difficult to get a system-wide spellchecker? Shit, I'd settle for an office suite one. Stupid unhelpful Windows\" => bigg boss\n",
      "'Last one month due to summer, strawberry is not availble in the Chennai markets!' => machine learning\n",
      "'@willxxmobb work at 6am. Gotta go to bed soon' => bollywood\n",
      "'@RobertF3 correct! I ADORE him. I just plucked him up and put him under my arm cuz he was cryin.  All better now! Hahaha' => cricket\n",
      "'@sweeetnspicy hiii im on my ipod...i cant fall asleep' => cricket\n",
      "'dont wanna work 11-830 tomorrow  but i get paid' => food\n",
      "'feels sad coz i wasnt able to play with the guys!!!  http://plurk.com/p/wxiux' => bollywood\n",
      "'PrinceCharming' => bigg boss\n",
      "\"@ cayogial i wanted to come to BZ this summer :/ not so sure anymore... a teacher's life in the summer SUCKS\" => hollywood\n",
      "'First ever dropped call on my mobile. On a call to @Telstra no less! ( being charged for data even though I have a data pack  )' => machine learning\n",
      "'@mrgenius23 You win ... SIGH Rakeem' => cricket\n",
      "'Oh is that time for real?' => cricket\n",
      "\"Darn these allergies! I don't like this time of year because of this! I never used to have this problem either\" => football\n",
      "'Oh no one minute too late! Oh well' => hollywood\n",
      "'@soviet_star Damn, that sucks' => cricket\n",
      "\"@cayogial i wanted to come to BZ this summer :/ not so sure anymore... a teacher's life in the summer SUCKS\" => machine learning\n",
      "'@mileycyrus THIS WEBSITE GAVE ME A VIRUS! When i opened it more windows kept POPPING up' => football\n",
      "'ahh! big scary bug flying around my room!!!!!' => cricket\n",
      "'I wish she knew what she puts me through..She stole my heart, never gave it back..and occasionally she likes to be like look what I have!' => cricket\n",
      "'is up with a nasty cough i cant be sick i have a huge weekend ahead of me' => hollywood\n",
      "'@justamedicine  That was stone cold   Crazy....  ?' => happy birthday\n",
      "\"i'm so tired\" => football\n",
      "'shift time  bbye biochem waaaaahhhhhh!! http://plurk.com/p/wxizo' => bollywood\n",
      "\"@melbournegirl I'm sure some1 will cum out and play. I'm workin through til midnight.\" => football\n",
      "'@thecreativeone I second that. I wish it rained more where I am' => bigg boss\n",
      "\"@neesabear early happy day of birth in case I don't make it! Very tired from therapy today n just taking my medicine!  misshu! Love ya!\" => machine learning\n",
      "'damn it were is Eric or anyone else when you need your hair to be played with' => food\n",
      "\"I'm feel deflated. Ugh. No more dog.\" => football\n",
      "'Allergies suck ducks nuts.     &lt;=====8@8=====&gt;' => happy birthday\n",
      "'Well it almost was a good day... Guess I just retry tomorrow' => food\n",
      "'@IamYeTe Waraku is tasteless and expensive! Portion is so little!!!!!  re: waraku' => machine learning\n",
      "\"@freepbx sounds good. Appreciate the suggestion. Been a week now and we're still offline  Time to ask for a refund...\" => cricket\n",
      "'@poinktoinkdoink He died.  Wait, what about Magic Jack? I just read it.' => football\n",
      "'@britblackbird  youstinkatrespondingtotexts!' => football\n",
      "'wonders why her Karma points turned into 0.00.  http://plurk.com/p/wxj54' => bollywood\n",
      "'Need to pack for CALI CALI! Cannot waittt! Thinking a glass of wine is in order to celebrate my weekend vaca. Still work 2morrow, tho.' => bigg boss\n",
      "'Is miserable  i feel like im gona cry  sux!' => machine learning\n",
      "'@megturney well I ran out of beer so I left. Not sure about the ETA. Waiting waiting waiting. Bleh  Gonna be a long nite methinks.' => bigg boss\n",
      "\"$#@! My nose stud fell out and I can't find it  Looks like I'll have to head into Amsterdam today and get a new one\" => cricket\n",
      "'claire @breakfastnt love the show, got into the office @ 5am and no radio' => food\n",
      "'Pats in philly at 2 am. I love it. Mmm cheesesteak.  Miss my boyfriend   but I love vacation.' => food\n",
      "\"*sigh* I'm going to bed... I just don't feel right anymore...\" => hollywood\n",
      "\"What? I focused on Tom so much I didn't see my beloved Barack! Oh no! I must vote for both! Poor president only has 626 votes.\" => bigg boss\n",
      "'@jwillock EpiCentre Wheelock Place - tourists only..' => football\n",
      "'Now I am depressed after watching so you think you can dance' => cricket\n",
      "\"Just cross 'cause I'm stuck twiddling my thumbs now, ugh\" => food\n",
      "\"miss 16'th\" => machine learning\n",
      "'@TheHarvardian I know. But like I said, I have no idea how long it takes for them to investigate this stuff.' => bigg boss\n",
      "'I cant sleep, but im too sore to move' => machine learning\n",
      "'@LaFloozita http://twitpic.com/4phze - Awe! I miss my baby' => machine learning\n",
      "'@softtouchme just answered you- never learned how to write in French- just basic stuff-' => hollywood\n",
      "'what is it with chocolates? i just can never say no' => football\n",
      "'Achieving a new appreciation on how a xml build script can really be painful and cumbersome' => food\n",
      "\"@ether_radio i'm too awake now  ill have a nap this afternoon\" => happy birthday\n",
      "'@omfgiselle i cant do anything' => bigg boss\n",
      "'still needs another 6 hours of sleep' => bollywood\n",
      "\"I'm at work\" => machine learning\n",
      "'RIP leonardo. You were a great mini fiddler crab' => football\n",
      "'Morning tweeple,way to early again' => football\n",
      "'Last day working for the Uni today, sad times' => hollywood\n",
      "\"@NisforNeemah thanks neemah. I'm gonna be soooo close to you and izzy, yet so far\" => bigg boss\n",
      "'My head hurts so bad I could scream!' => football\n",
      "'i just go up and IM SO TIRED and my airmatras is broken somewhere and now im in even more pain' => bollywood\n",
      "'New work wellness challenge not going well.  I committed to not check email between 10 pm and 6 am.  Failed on first day.  Twice' => football\n",
      "'New blog post: [Blog] auto insuran...: I just found that my auto insurance policy had been expired. ( I am too careless  ...) .. Meanw ...' => happy birthday\n",
      "'where are all ma bestfriends at ? , MIA or wat ?' => happy birthday\n",
      "\"oh men!!!!!!......I really can't see my face........c'mon guys!!!\" => bollywood\n",
      "\"I'm showing my age. Renewed my tags last week, went down $20. Got my insurance renewal email today, went down $100. I don't wanna be old\" => football\n",
      "'my sole supporter is not my sole supporter' => food\n",
      "\"don't you hate it when you finish all your work and there's still 1.25 hours left of work time\" => food\n",
      "'@Emilyyy16 urgh stop it guys' => bollywood\n",
      "'is still missing her husband.    I really want him home.' => bigg boss\n",
      "'I miss my puppy' => hollywood\n",
      "'2 days of this month left, and I only have 400MB left on my onpeak downloads.' => machine learning\n",
      "\"@IdleThumbs Up is out?  I didn't get the memo   It looks amazing.\" => food\n",
      "\"@nzdeany I've given up on pizza - kids would never let me have my fav  (the hot ones)\" => food\n",
      "\"Up reading tabloids about other people's lives...thinking what I'm gonna do with mine when my baby leaves?\" => mobiles\n",
      "'@BarbSchaefer yearling in pet home died... very sad for their whole family' => happy birthday\n",
      "\"fun in the sun hmmm hell no it's cold\" => food\n",
      "'I got a giant splinter stuck up underneath my finger nail today at Muppets...it hurt.  But I got to go to First Aid for the first time!' => food\n",
      "\"@heresmyhello92 We hate change, so of course. We're fans for life. &lt;3 Oh and if we haven't met Rob by then something went horribly wrong.\" => machine learning\n",
      "'is feeling sad... for some reason..  http://plurk.com/p/wxji3' => hollywood\n",
      "\"well fuck- this new pain med has an odd warning that actually applies to me. i can't take this. -chan is displeased.\" => machine learning\n",
      "'just uploaded my new blog... a painful story about an 80s year old man who cried because he wanted to die... very sad' => happy birthday\n",
      "\"@juneyee i don't think so.  I WANT DETAILS.\" => machine learning\n",
      "'@jackgraycnn Hi...!!! Who is Mary Poppins???' => football\n",
      "'@jaychuck Its so addicting, but its kind of a curse to do them at night time. Everytime i do one, i feel like making music afterwards' => machine learning\n",
      "\"my last tweet didn't send  bad phone\" => football\n",
      "\"@relly1  OMG Ur alive!!! LOL  2day has gone sooo slow  I'm going insane Grrr You doing anything tonight?\" => food\n",
      "\"Have a headache  I'm going to bed. Goodnight!\" => bollywood\n",
      "'@taxidermi  I was watching Parental Control' => bigg boss\n",
      "'@JessiJaeJoplin did you get them from california vintage? ahahah they have the BEST dresses, i want them but i dont have ebay' => bollywood\n",
      "'I just saw pics from this past Thanksgiving and am sad because Grandma was in them.' => food\n",
      "'@jertronic it wont let me' => bollywood\n",
      "\"Took a shift tomorrow.    I don't really feel like working right now.\" => hollywood\n",
      "'but now i have no money for a phone' => football\n",
      "'Spent last night in A&amp;E (ER). Wife tangled wheels with Daughter &amp; hit the deck. Dislocation &amp; fracture resulted.' => machine learning\n",
      "\"@TheLastDoctor 9 days  I'm about ready to visit Torchwood and see if they've heard anything\" => food\n",
      "\"@Bern_morley where are you? In Bris? I can't hear any thunder\" => cricket\n",
      "'bec vs fat food   --- winner = fat food  but not this weeknend, ill beat it!' => food\n",
      "'Too bad the Red Devils.. disappointing to say the least' => food\n",
      "'I had a dream about a pretty pretty beach and there was no beach when I woke up' => happy birthday\n",
      "'@xdjio Have a 3ware 9650SE, not fast enough for 3x X25-M SSD RAID5. 800Mhz IOP on the HPT. Might try an Adaptec 5405 (1.2Ghz).' => food\n",
      "'when da heck will the garage man get here I ask you.. WHEN..' => cricket\n",
      "\"Ate Mandy, please forgive me. I really am sorry. I don't wanna lose my Bff\" => happy birthday\n",
      "\"@melluffsyew Umm yeah. That's probably a pretty good note to self because eeeeeewwwwwwww.\" => hollywood\n",
      "'why are plane tickets so expensive' => happy birthday\n",
      "\"(@wendyisastar) @melluffsyew Umm yeah. That's probably a pretty good note to self because eeeeeewwwwwwww.\" => food\n",
      "'Needs a job BADLY!!!' => machine learning\n",
      "'@AlexanderGWhite daaammmnnnnn I do wish I was there.' => bollywood\n"
     ]
    }
   ],
   "source": [
    "# for x in real_predicted:\n",
    "#     print(x)\n",
    "\n",
    "## predictions for first 10 test samples\n",
    "\n",
    "counter  = 0\n",
    "for doc, category in zip(x_tt, real_predicted):\n",
    "    print('%r => %s' % (doc, category))\n",
    "    if(counter == 200):\n",
    "        break\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  results  already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "dirName = 'results'\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "## predictions for first 10 test samples\n",
    "text_hollywood = ''\n",
    "text_bollywood = ''\n",
    "text_ml = ''\n",
    "text_football = ''\n",
    "text_bigg_boss = ''\n",
    "text_food = '' \n",
    "text_hp_day = ''\n",
    "text_politics = ''\n",
    "text_mobiles = ''\n",
    "text_cricket = ''\n",
    "counter  = 0\n",
    "for doc, category in zip(x_test, real_predicted):\n",
    "    if category == \"hollywood\":\n",
    "        f= open('results/'+ category+\".txt\",\"w+\")\n",
    "        if (text_hollywood != \"\"):\n",
    "            text_hollywood = text_hollywood + '\\n' + doc\n",
    "        else:\n",
    "            text_hollywood = doc\n",
    "        f.write(text_hollywood)\n",
    "        f.close()\n",
    "    if category == \"bollywood\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_bollywood != \"\"):\n",
    "            text_bollywood = text_bollywood + '\\n' + doc\n",
    "        else:\n",
    "            text_bollywood = doc\n",
    "        f.write(text_bollywood)\n",
    "        f.close()\n",
    "    if category == \"machine learning\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_ml != \"\"):\n",
    "            text_ml = text_ml + '\\n' + doc\n",
    "        else:\n",
    "            text_ml = doc\n",
    "        f.write(text_ml)\n",
    "        f.close()\n",
    "    if category == \"football\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_football != \"\"):\n",
    "            text_football = text_football + '\\n' + doc\n",
    "        else:\n",
    "            text_football = doc\n",
    "        f.write(text_football)\n",
    "        f.close()\n",
    "    if category == \"bigg boss\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_bigg_boss != \"\"):\n",
    "            text_bigg_boss = text_bigg_boss + '\\n' + doc\n",
    "        else:\n",
    "            text_bigg_boss = doc\n",
    "        f.write(text_bigg_boss)\n",
    "        f.close()\n",
    "    if category == \"food\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_food != \"\"):\n",
    "            text_food = text_food + '\\n' + doc\n",
    "        else:\n",
    "            text_food = doc\n",
    "        f.write(text_food)\n",
    "        f.close()\n",
    "    if category == \"happy birthday\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_hp_day != \"\"):\n",
    "            text_hp_day = text_hp_day + '\\n' + doc\n",
    "        else:\n",
    "            text_hp_day = doc\n",
    "        f.write(text_hp_day)\n",
    "        f.close() \n",
    "    if category == \"politics\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_politics != \"\"):\n",
    "            text_politics = text_politics + '\\n' + doc\n",
    "        else:\n",
    "            text_politics = doc\n",
    "        f.write(text_politics)\n",
    "        f.close() \n",
    "    if category == \"mobiles\":\n",
    "        f= open('results/'+category+\".txt\",\"w+\")\n",
    "        if (text_mobiles != \"\"):\n",
    "            text_mobiles = text_mobiles + '\\n' + doc\n",
    "        else:\n",
    "            text_mobiles = doc\n",
    "        f.write(text_mobiles)\n",
    "        f.close()\n",
    "    if category == \"cricket\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_cricket != \"\"):\n",
    "            text_cricket = text_cricket + '\\n' + doc\n",
    "        else:\n",
    "            text_cricket = doc\n",
    "        f.write(text_cricket)\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy achieved is 0.9393767705382436\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "       bollywood       1.00      0.82      0.90       327\n",
      "       hollywood       0.88      0.93      0.91       993\n",
      "        politics       0.99      0.97      0.98       986\n",
      "         cricket       0.96      0.95      0.96       965\n",
      "            food       0.89      0.98      0.93      1005\n",
      "        football       0.96      0.93      0.94       589\n",
      "         mobiles       0.94      0.90      0.92      1071\n",
      "machine learning       0.94      0.99      0.96       990\n",
      "       bigg boss       1.00      0.82      0.90        91\n",
      "  happy birthday       1.00      0.40      0.57        43\n",
      "\n",
      "        accuracy                           0.94      7060\n",
      "       macro avg       0.96      0.87      0.90      7060\n",
      "    weighted avg       0.94      0.94      0.94      7060\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[267,  27,   3,   2,  14,   5,   8,   1,   0,   0],\n",
       "       [  0, 928,   2,   5,   9,   8,  30,  11,   0,   0],\n",
       "       [  0,   3, 960,   1,  17,   0,   4,   1,   0,   0],\n",
       "       [  0,  10,   0, 918,  17,   2,   7,  11,   0,   0],\n",
       "       [  0,   3,   0,   3, 987,   0,   4,   8,   0,   0],\n",
       "       [  0,   9,   1,  13,  17, 545,   3,   1,   0,   0],\n",
       "       [  0,  50,   0,   9,  31,   6, 959,  16,   0,   0],\n",
       "       [  0,   2,   0,   1,   9,   0,   2, 976,   0,   0],\n",
       "       [  0,   4,   0,   1,   3,   0,   1,   7,  75,   0],\n",
       "       [  0,  16,   0,   0,   8,   0,   1,   1,   0,  17]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy achieved is ' + str(np.mean(real_predicted == y_test)))\n",
    "print(metrics.classification_report(y_test, real_predicted, target_names=categories)),\n",
    "metrics.confusion_matrix(y_test, real_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
