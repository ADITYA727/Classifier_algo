{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as j\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = None\n",
    "data = pd.read_csv(\"data_large_5000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "data['tweets'] = data['tweets'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.tweets\n",
    "y = data.tagname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('vect', TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\", sublinear_tf=True)),\n",
    "                     ('chi',  SelectKBest(chi2, k=10000)),\n",
    "                     ('clf', LinearSVC(C=1.0, penalty='l1', max_iter=3000, dual=False))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pipeline.fit(X_train, y_train)\n",
    "\n",
    "vectorizer = model.named_steps['vect']\n",
    "chi = model.named_steps['chi']\n",
    "clf = model.named_steps['clf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "feature_names = [feature_names[i] for i in chi.get_support(indices=True)]\n",
    "feature_names = np.asarray(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  results  already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "dirName = 'results'\n",
    " \n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "## predictions for first 10 test samples\n",
    "text_hollywood = ''\n",
    "text_bollywood = ''\n",
    "text_ml = ''\n",
    "text_football = ''\n",
    "text_bigg_boss = ''\n",
    "text_food = '' \n",
    "text_hp_day = ''\n",
    "text_politics = ''\n",
    "text_mobiles = ''\n",
    "text_cricket = ''\n",
    "counter  = 0\n",
    "for doc, category in zip(X_test, predict):\n",
    "    if category == \"hollywood\":\n",
    "        f= open('results/'+ category+\".txt\",\"w+\")\n",
    "        if (text_hollywood != \"\"):\n",
    "            text_hollywood = text_hollywood + '\\n' + doc\n",
    "        else:\n",
    "            text_hollywood = doc\n",
    "        f.write(text_hollywood)\n",
    "        f.close()\n",
    "    if category == \"bollywood\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_bollywood != \"\"):\n",
    "            text_bollywood = text_bollywood + '\\n' + doc\n",
    "        else:\n",
    "            text_bollywood = doc\n",
    "        f.write(text_bollywood)\n",
    "        f.close()\n",
    "    if category == \"machine learning\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_ml != \"\"):\n",
    "            text_ml = text_ml + '\\n' + doc\n",
    "        else:\n",
    "            text_ml = doc\n",
    "        f.write(text_ml)\n",
    "        f.close()\n",
    "    if category == \"football\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_football != \"\"):\n",
    "            text_football = text_football + '\\n' + doc\n",
    "        else:\n",
    "            text_football = doc\n",
    "        f.write(text_football)\n",
    "        f.close()\n",
    "    if category == \"bigg boss\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_bigg_boss != \"\"):\n",
    "            text_bigg_boss = text_bigg_boss + '\\n' + doc\n",
    "        else:\n",
    "            text_bigg_boss = doc\n",
    "        f.write(text_bigg_boss)\n",
    "        f.close()\n",
    "    if category == \"food\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_food != \"\"):\n",
    "            text_food = text_food + '\\n' + doc\n",
    "        else:\n",
    "            text_food = doc\n",
    "        f.write(text_food)\n",
    "        f.close()\n",
    "    if category == \"happy birthday\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_hp_day != \"\"):\n",
    "            text_hp_day = text_hp_day + '\\n' + doc\n",
    "        else:\n",
    "            text_hp_day = doc\n",
    "        f.write(text_hp_day)\n",
    "        f.close() \n",
    "    if category == \"politics\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_politics != \"\"):\n",
    "            text_politics = text_politics + '\\n' + doc\n",
    "        else:\n",
    "            text_politics = doc\n",
    "        f.write(text_politics)\n",
    "        f.close() \n",
    "    if category == \"mobiles\":\n",
    "        f= open('results/'+category+\".txt\",\"w+\")\n",
    "        if (text_mobiles != \"\"):\n",
    "            text_mobiles = text_mobiles + '\\n' + doc\n",
    "        else:\n",
    "            text_mobiles = doc\n",
    "        f.write(text_mobiles)\n",
    "        f.close()\n",
    "    if category == \"cricket\":\n",
    "        f= open('results/'+ category +\".txt\",\"w+\")\n",
    "        if (text_cricket != \"\"):\n",
    "            text_cricket = text_cricket + '\\n' + doc\n",
    "        else:\n",
    "            text_cricket = doc\n",
    "        f.write(text_cricket)\n",
    "        f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5  Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords per class:\n",
      "1: ko goosebump hina bigg shukla india bigg boss asim shilpa shilpashind bb\n",
      "2: kartikaaryan birthday boy team firstbuzz marjaavaan khan cineplex sanayairani aishwaryaraibachchan salmankhan bollywood\n",
      "3: ipl bharatarmyaward sanjusamson bringbackdhoni west indi sanju selector indvssl odi teamindia\n",
      "4: italian boston bruin italianfood food itali pizza lezzet recip spaghetti pasta\n",
      "5: arsenal liverpool sack spur frank footbal tottenham giroud mourinho chelsea\n",
      "accuracy score: 0.9498583569405099\n"
     ]
    }
   ],
   "source": [
    "target_names = ['1', '2', '3', '4', '5']\n",
    "print(\"top 10 keywords per class:\")\n",
    "for i, label in enumerate(target_names):\n",
    "    top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "    print(\"%s: %s\" % (label, \" \".join(feature_names[top10])))\n",
    "\n",
    "print(\"accuracy score: \" + str(model.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
